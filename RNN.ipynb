{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd035308-996c-44cc-bda3-37681585fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.version.cuda: 12.8\n",
      "torch.cuda.is_available(): True\n",
      "torch.xpu.is_available(): False\n",
      "‚úÖ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π: cuda\n",
      "   –ö–∞—Ä—Ç–∞: NVIDIA GeForce RTX 5070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import calendar\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU (–∫–∞–∫ –º—ã –¥–µ–ª–∞–ª–∏ —Ä–∞–Ω—å—à–µ)\n",
    "# –ï—Å–ª–∏ CUDA –µ—Å—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë. –ï—Å–ª–∏ –Ω–µ—Ç - –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä.\n",
    "\n",
    "print(f\"torch.version.cuda: {torch.version.cuda}\")       # –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å '12.4' –∏–ª–∏ '12.1' (–Ω–µ None!)\n",
    "print(f\"torch.cuda.is_available(): {torch.cuda.is_available()}\") # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å True\n",
    "print(f\"torch.xpu.is_available(): {torch.xpu.is_available()}\") \n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ç—Ä–∏–±—É—Ç xpu, —á—Ç–æ–±—ã –∫–æ–¥ –Ω–µ –ø–∞–¥–∞–ª –Ω–∞ –º–∞—à–∏–Ω–∞—Ö —Å–æ —Å—Ç–∞—Ä—ã–º PyTorch\n",
    "    elif hasattr(torch, 'xpu') and torch.xpu.is_available():\n",
    "        return torch.device(\"xpu\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "\n",
    "print(f\"‚úÖ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π: {device}\")\n",
    "# –ï—Å–ª–∏ XPU –∞–∫—Ç–∏–≤–µ–Ω, –ø–æ–ª–µ–∑–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ –∏–º—è –∫–∞—Ä—Ç—ã:\n",
    "if device.type == 'xpu':\n",
    "    print(f\"   –ö–∞—Ä—Ç–∞: {torch.xpu.get_device_name(0)}\")\n",
    "elif device.type == 'cuda':\n",
    "    print(f\"   –ö–∞—Ä—Ç–∞: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67bfafb8-4f0a-4b8b-b468-dcfef7803c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version: 3.10.12 (main, Nov  4 2025, 08:48:33) [GCC 11.4.0]\n",
      "platform.python_version(): 3.10.12\n"
     ]
    }
   ],
   "source": [
    "print(f\"sys.version: {sys.version}\")\n",
    "\n",
    "print(f\"platform.python_version(): {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71669525-1843-4572-814a-10da7b8e4cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('11 May 1171', '<1171-05-11>')\n"
     ]
    }
   ],
   "source": [
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug',\n",
    "          'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "\n",
    "def generate_date():\n",
    "    year = random.randint(1000, 2100)\n",
    "\n",
    "    monthIdx = random.randint(1, 12)\n",
    "\n",
    "    match monthIdx:\n",
    "        case 1 | 3 | 5 | 7 | 8 | 10 | 12:\n",
    "            day = random.randint(1, 31)\n",
    "        case 4 | 6 | 9 | 11:\n",
    "            day = random.randint(1, 30)\n",
    "        case 2:\n",
    "            if calendar.isleap(year):\n",
    "                day = random.randint(1, 29)\n",
    "            else:\n",
    "                day = random.randint(1, 28)\n",
    "\n",
    "    # 1. –ü–æ—Ä—è–¥–æ–∫: –ì–æ–¥ - –ú–µ—Å—è—Ü - –î–µ–Ω—å\n",
    "    # 2. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ :02d –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–ª—å –≤ –Ω–∞—á–∞–ª–µ, –µ—Å–ª–∏ —á–∏—Å–ª–æ < 10 (–Ω–∞–ø—Ä–∏–º–µ—Ä, 05)\n",
    "    tgt_str = f'{year}-{monthIdx:02d}-{day:02d}'\n",
    "\n",
    "    # –í—Ö–æ–¥ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å: \"25 Jan 2023\"\n",
    "    src_str = f'{day} {months[monthIdx-1]} {year}'\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä—ã —Å—Ç–∞—Ä—Ç–∞ –∏ —Å—Ç–æ–ø–∞\n",
    "    tgt_str = f'<{tgt_str}>'\n",
    "\n",
    "    return src_str, tgt_str\n",
    "\n",
    "\n",
    "print(generate_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95eb8910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º 50000 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ (–≥–æ–¥—ã 1000-2100)...\n",
      "‚úÖ –ì–æ—Ç–æ–≤–æ! Train: 40000, Test: 10000\n"
     ]
    }
   ],
   "source": [
    "TOTAL_SAMPLES = 50000\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "print(f\"üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º {TOTAL_SAMPLES} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ (–≥–æ–¥—ã 1000-2100)...\")\n",
    "\n",
    "dataset_set = set()\n",
    "\n",
    "# –¢–µ–ø–µ—Ä—å —ç—Ç–æ—Ç —Ü–∏–∫–ª –Ω–µ –∑–∞–≤–∏—Å–Ω–µ—Ç, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (400k) > —Ü–µ–ª–∏ (50k)\n",
    "while len(dataset_set) < TOTAL_SAMPLES:\n",
    "    dataset_set.add(generate_date())\n",
    "\n",
    "full_dataset = list(dataset_set)\n",
    "random.shuffle(full_dataset)\n",
    "\n",
    "split_index = int(TOTAL_SAMPLES * TRAIN_RATIO)\n",
    "train_data = full_dataset[:split_index]\n",
    "test_data = full_dataset[split_index:]\n",
    "\n",
    "print(f\"‚úÖ –ì–æ—Ç–æ–≤–æ! Train: {len(train_data)}, Test: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaff16cf-22d2-4ca1-9172-e19bd77d115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char2idx: {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, ' ': 3, '-': 4, '0': 5, '1': 6, '2': 7, '3': 8, '4': 9, '5': 10, '6': 11, '7': 12, '8': 13, '9': 14, '<': 15, '>': 16, 'A': 17, 'B': 18, 'C': 19, 'D': 20, 'E': 21, 'F': 22, 'G': 23, 'H': 24, 'I': 25, 'J': 26, 'K': 27, 'L': 28, 'M': 29, 'N': 30, 'O': 31, 'P': 32, 'Q': 33, 'R': 34, 'S': 35, 'T': 36, 'U': 37, 'V': 38, 'W': 39, 'X': 40, 'Y': 41, 'Z': 42, 'a': 43, 'b': 44, 'c': 45, 'd': 46, 'e': 47, 'f': 48, 'g': 49, 'h': 50, 'i': 51, 'j': 52, 'k': 53, 'l': 54, 'm': 55, 'n': 56, 'o': 57, 'p': 58, 'q': 59, 'r': 60, 's': 61, 't': 62, 'u': 63, 'v': 64, 'w': 65, 'x': 66, 'y': 67, 'z': 68}\n",
      "idx2char: {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: ' ', 4: '-', 5: '0', 6: '1', 7: '2', 8: '3', 9: '4', 10: '5', 11: '6', 12: '7', 13: '8', 14: '9', 15: '<', 16: '>', 17: 'A', 18: 'B', 19: 'C', 20: 'D', 21: 'E', 22: 'F', 23: 'G', 24: 'H', 25: 'I', 26: 'J', 27: 'K', 28: 'L', 29: 'M', 30: 'N', 31: 'O', 32: 'P', 33: 'Q', 34: 'R', 35: 'S', 36: 'T', 37: 'U', 38: 'V', 39: 'W', 40: 'X', 41: 'Y', 42: 'Z', 43: 'a', 44: 'b', 45: 'c', 46: 'd', 47: 'e', 48: 'f', 49: 'g', 50: 'h', 51: 'i', 52: 'j', 53: 'k', 54: 'l', 55: 'm', 56: 'n', 57: 'o', 58: 'p', 59: 'q', 60: 'r', 61: 's', 62: 't', 63: 'u', 64: 'v', 65: 'w', 66: 'x', 67: 'y', 68: 'z'}\n",
      "–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤): 69\n",
      "–ò–Ω–¥–µ–∫—Å –±—É–∫–≤—ã 'A': 17\n",
      "–°–∏–º–≤–æ–ª –ø–æ–¥ –∏–Ω–¥–µ–∫—Å–æ–º 10: 5\n",
      "–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è —Å —Ç–æ–∫–µ–Ω–∞–º–∏: 69\n",
      "–ò–Ω–¥–µ–∫—Å <PAD>: 0\n",
      "–ò–Ω–¥–µ–∫—Å <EOS>: 2\n"
     ]
    }
   ],
   "source": [
    "# 0. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏ –∏—Ö –∏–Ω–¥–µ–∫—Å—ã (–∑–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º –∏—Ö –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞)\n",
    "# –í–∞–∂–Ω–æ: 0-–π –∏–Ω–¥–µ–∫—Å —á–∞—Å—Ç–æ —Ä–µ–∑–µ—Ä–≤–∏—Ä—É—é—Ç –¥–ª—è PAD, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "# –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –Ω—É–ª—è–º–∏.\n",
    "PAD_token = 0\n",
    "SOS_token = 1 \n",
    "EOS_token = 2\n",
    "\n",
    "# –°–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –±—É–¥—É—Ç –≤ –Ω–∞—à–µ–º —Å–ª–æ–≤–∞—Ä–µ\n",
    "special_chars = {\n",
    "    '<PAD>': PAD_token, \n",
    "    '<SOS>': SOS_token, \n",
    "    '<EOS>': EOS_token\n",
    "}\n",
    "\n",
    "\n",
    "# 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (Alphabet)\n",
    "# set() —É–±–∏—Ä–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã\n",
    "chars = set(\"0123456789 abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ<>-\")\n",
    "\n",
    "# 2. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–∏–º–≤–æ–ª—ã –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è char2idx\n",
    "# –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Å 3 (–ø–æ—Å–ª–µ 0, 1, 2)\n",
    "sorted_data_chars = sorted(chars)\n",
    "next_index = len(special_chars)\n",
    "\n",
    "# 3. –°–æ–∑–¥–∞–µ–º Map: –°–∏–º–≤–æ–ª -> –ò–Ω–¥–µ–∫—Å (Integer)\n",
    "# sorted() —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ–±—ã –ø–æ—Ä—è–¥–æ–∫ –≤—Å–µ–≥–¥–∞ –±—ã–ª –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º\n",
    "# enumerate() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä—ã (—Å—á–µ—Ç—á–∏–∫, —ç–ª–µ–º–µ–Ω—Ç)\n",
    "char2idx = special_chars.copy()\n",
    "char2idx.update({char: idx + next_index for idx, char in enumerate(sorted_data_chars)})\n",
    "print(f\"char2idx: {char2idx}\")\n",
    "\n",
    "# 3. –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–π Map: –ò–Ω–¥–µ–∫—Å -> –°–∏–º–≤–æ–ª (–¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞)\n",
    "idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "\n",
    "print(f\"idx2char: {idx2char}\")\n",
    "\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–π —Ç–æ–∫–µ–Ω \"EOS\" (End Of Sentence) –∏–ª–∏ PAD, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "# –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–æ–º–Ω–∏–º —Ä–∞–∑–º–µ—Ä –Ω–∞—à–µ–≥–æ \"–∞–ª—Ñ–∞–≤–∏—Ç–∞\"\n",
    "vocab_size = len(char2idx)\n",
    "\n",
    "print(f\"–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤): {vocab_size}\")\n",
    "print(f\"–ò–Ω–¥–µ–∫—Å –±—É–∫–≤—ã 'A': {char2idx['A']}\")\n",
    "print(f\"–°–∏–º–≤–æ–ª –ø–æ–¥ –∏–Ω–¥–µ–∫—Å–æ–º 10: {idx2char[10]}\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è —Å —Ç–æ–∫–µ–Ω–∞–º–∏: {vocab_size}\")\n",
    "print(f\"–ò–Ω–¥–µ–∫—Å <PAD>: {char2idx['<PAD>']}\")\n",
    "print(f\"–ò–Ω–¥–µ–∫—Å <EOS>: {char2idx['<EOS>']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faafb3de-4775-4951-8f19-b5ef95865d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Packed Encoder –≥–æ—Ç–æ–≤.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class EncoderRNN_Packed(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN_Packed, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    # –î–æ–±–∞–≤–∏–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç lengths (–¥–ª–∏–Ω—ã —Ñ—Ä–∞–∑ –≤ –±–∞—Ç—á–µ)\n",
    "    def forward(self, input, lengths, hidden):\n",
    "        embedded = self.embedding(input)\n",
    "        \n",
    "        # 1. –£–ü–ê–ö–û–í–ö–ê (PACKING)\n",
    "        # –ú—ã –≥–æ–≤–æ—Ä–∏–º RNN: \"–ò–≥–Ω–æ—Ä–∏—Ä—É–π —Ö–≤–æ—Å—Ç—ã!\"\n",
    "        # enforce_sorted=False –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –±–∞—Ç—á –ø–æ –¥–ª–∏–Ω–µ (—É–¥–æ–±–Ω–æ!)\n",
    "        packed = pack_padded_sequence(embedded, lengths.cpu(), enforce_sorted=False)\n",
    "        \n",
    "        # 2. –ü–†–û–ì–û–ù (—É–∂–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)\n",
    "        output, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        # 3. –†–ê–°–ü–ê–ö–û–í–ö–ê (UNPACKING)\n",
    "        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å—ë –≤ –ø—Ä–∏–≤—ã—á–Ω—ã–π –≤–∏–¥ (—Å –Ω—É–ª—è–º–∏), —á—Ç–æ–±—ã –î–µ–∫–æ–¥–µ—Ä –º–æ–≥ —Ä–∞–±–æ—Ç–∞—Ç—å\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "\n",
    "print(\"‚úÖ Packed Encoder –≥–æ—Ç–æ–≤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5555b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked Decoder –≥–æ—Ç–æ–≤.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class AttnDecoderRNN_Masked(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, max_length=15, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN_Masked, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_length = max_length\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    # –î–æ–±–∞–≤–∏–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç encoder_mask\n",
    "    def forward(self, input, hidden, encoder_outputs, encoder_mask):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_input = torch.cat((embedded[0], hidden[0]), 1) \n",
    "        \n",
    "        # 1. –°—á–∏—Ç–∞–µ–º \"—Å—ã—Ä—ã–µ\" —ç–Ω–µ—Ä–≥–∏–∏ (–¥–æ Softmax)\n",
    "        attn_energies = self.attn(attn_input) # (Batch, Max_Len)\n",
    "\n",
    "        # 2. –ü–†–ò–ú–ï–ù–Ø–ï–ú –ú–ê–°–ö–£!\n",
    "        if encoder_mask is not None:\n",
    "            # –¢–∞–º, –≥–¥–µ –º–∞—Å–∫–∞ == 0 (PAD), —Å—Ç–∞–≤–∏–º -1 –º–∏–ª–ª–∏–∞—Ä–¥.\n",
    "            # Softmax(-1e9) -> 0.0\n",
    "            attn_energies = attn_energies.masked_fill(encoder_mask == 0, -1e4)\n",
    "\n",
    "        # 3. –¢–µ–ø–µ—Ä—å –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–µ–ª–∞–µ–º Softmax\n",
    "        attn_weights = F.softmax(attn_energies, dim=1)\n",
    "\n",
    "        encoder_outputs_transposed = encoder_outputs.transpose(0, 1)\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                 encoder_outputs_transposed)\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[:, 0, :]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0) \n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "print(\"‚úÖ Masked Decoder –≥–æ—Ç–æ–≤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3d83fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ú–∞—Ä–∫–µ—Ä –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–∫–∏ (End Of Sentence).\n",
    "# –í –Ω–∞—à–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ –º—ã –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –¥–∞—Ç—É –≤ <...>.\n",
    "# –ó–Ω–∞—á–∏—Ç, —Å–∏–º–≤–æ–ª–æ–º –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –±—É–¥–µ—Ç '>'.\n",
    "EOS_token = char2idx['>']\n",
    "\n",
    "def tensorFromSentence(sentence):\n",
    "    # 1. –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä–æ–∫—É –≤ —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤\n",
    "    indexes = [char2idx[char] for char in sentence]\n",
    "    \n",
    "    # 2. –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä –∫–æ–Ω—Ü–∞ \n",
    "    # –í –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ '>' —É–∂–µ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏ –æ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞, \n",
    "    # –Ω–æ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–Ω —Ç–∞–º –µ—Å—Ç—å.\n",
    "    indexes.append(EOS_token)\n",
    "    \n",
    "    # 3. –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ –¢–µ–Ω–∑–æ—Ä\n",
    "    # dtype=torch.long –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è –∏–Ω–¥–µ–∫—Å–æ–≤ (Embedding —Å–ª–æ–π —Ç—Ä–µ–±—É–µ—Ç long)\n",
    "    # .view(-1, 1) –¥–µ–ª–∞–µ—Ç –∏–∑ –≤–µ–∫—Ç–æ—Ä–∞ —Å—Ç–æ–ª–±–∏–∫ (Sequence Length x Batch Size)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "917216c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_packed(input_batch, target_batch, encoder, decoder, \n",
    "                       encoder_optimizer, decoder_optimizer, criterion, scaler = None):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    batch_size = input_batch.size(1)\n",
    "    target_len = target_batch.size(0)\n",
    "\n",
    "    with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "\n",
    "        # --- –°–ß–ò–¢–ê–ï–ú –î–õ–ò–ù–´ ---\n",
    "        # input_batch: (Seq_Len, Batch). –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º -> (Batch, Seq_Len)\n",
    "        # –°—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ –ù–ï-–Ω—É–ª–µ–π –≤ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ\n",
    "        # .cpu() –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è pack_padded_sequence –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö\n",
    "        lengths = (input_batch.transpose(0, 1) != PAD_token).sum(dim=1).cpu()\n",
    "        \n",
    "        # ---------------------\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "        \n",
    "        # –ü–ï–†–ï–î–ê–ï–ú –î–õ–ò–ù–´ –í –≠–ù–ö–û–î–ï–†!\n",
    "        encoder_outputs, encoder_hidden = encoder(input_batch, lengths, encoder_hidden)\n",
    "        \n",
    "        # –ú–∞—Å–∫–∞ –¥–ª—è Attention (—Ç–∞ –∂–µ –ª–æ–≥–∏–∫–∞, —á—Ç–æ –∏ —Ä–∞–Ω—å—à–µ)\n",
    "        mask = (input_batch.transpose(0, 1) != PAD_token)\n",
    "        full_mask = torch.zeros(batch_size, decoder.max_length, dtype=torch.bool, device=device)\n",
    "        actual_len = mask.size(1)\n",
    "        limit_len = min(actual_len, decoder.max_length)\n",
    "        full_mask[:, :limit_len] = mask[:, :limit_len]\n",
    "        \n",
    "        # Pad encoder outputs\n",
    "        proj_encoder_outputs = torch.zeros(decoder.max_length, batch_size, encoder.hidden_size, device=device)\n",
    "        # output –æ—Ç pad_packed_sequence –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–æ—Ä–æ—á–µ max_length, –µ—Å–ª–∏ –≤—Å–µ —Ñ—Ä–∞–∑—ã –∫–æ—Ä–æ—Ç–∫–∏–µ\n",
    "        out_len = encoder_outputs.size(0) \n",
    "        limit_copy = min(out_len, decoder.max_length)\n",
    "        proj_encoder_outputs[:limit_copy, :, :] = encoder_outputs[:limit_copy, :, :]\n",
    "\n",
    "        # –î–µ–∫–æ–¥–µ—Ä (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)\n",
    "        decoder_input = torch.tensor([[SOS_token] * batch_size], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            for di in range(target_len):\n",
    "                decoder_output, decoder_hidden, _ = decoder(\n",
    "                    decoder_input, decoder_hidden, proj_encoder_outputs, encoder_mask=full_mask)\n",
    "                loss += criterion(decoder_output, target_batch[di])\n",
    "                decoder_input = target_batch[di].unsqueeze(0) \n",
    "        else:\n",
    "            for di in range(target_len):\n",
    "                decoder_output, decoder_hidden, _ = decoder(\n",
    "                    decoder_input, decoder_hidden, proj_encoder_outputs, encoder_mask=full_mask)\n",
    "                loss += criterion(decoder_output, target_batch[di])\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.transpose(0, 1).detach()\n",
    "    \n",
    "    if scaler is not None:\n",
    "        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º Loss, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤ float16\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # –í–∞–∂–Ω–æ! –ü–µ—Ä–µ–¥ –∫–ª–∏–ø–ø–∏–Ω–≥–æ–º (–æ–±—Ä–µ–∑–∫–æ–π) –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –∏—Ö –Ω—É–∂–Ω–æ \"—Ä–∞–∑–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å\" (unscale)\n",
    "        scaler.unscale_(encoder_optimizer)\n",
    "        scaler.unscale_(decoder_optimizer)\n",
    "        \n",
    "        # –¢–µ–ø–µ—Ä—å –±–µ–∑–æ–ø–∞—Å–Ω–æ —Ä–µ–∂–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), 5.0)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), 5.0)\n",
    "        \n",
    "        # –®–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ —á–µ—Ä–µ–∑ —Å–∫–∞–ª–µ—Ä\n",
    "        scaler.step(encoder_optimizer)\n",
    "        scaler.step(decoder_optimizer)\n",
    "        \n",
    "        # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞—Å—à—Ç–∞–± –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏\n",
    "        scaler.update()\n",
    "        \n",
    "    else:\n",
    "        # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º (Fallback –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), 5.0)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), 5.0)\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3089181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–§–æ—Ä–º–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ (Seq_Len, Batch): torch.Size([12, 3])\n",
      "–§–æ—Ä–º–∞ —Ü–µ–ª–µ–≤–æ–≥–æ –±–∞—Ç—á–∞ (Seq_Len, Batch): torch.Size([11, 3])\n",
      "\n",
      "–ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ (–≤–∏–¥–∏–º –Ω—É–ª–∏-–ø–∞–¥–¥–∏–Ω–≥–∏ –≤ –∫–æ–Ω—Ü–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ—Ä–∞–∑?):\n",
      "tensor([[ 7, 14,  3, 35, 47, 58,  3,  7,  5, 14, 12, 16],\n",
      "        [11,  3, 17, 63, 49,  3,  6,  7,  5,  7, 16,  0],\n",
      "        [ 9,  3, 30, 57, 64,  3,  6, 10,  5, 11, 16,  0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –°—Ç—Ä–æ–∫–∞ -> –°–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤\n",
    "def indexesFromSentence(sentence):\n",
    "    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –º–∞—Ä–∫–µ—Ä—ã < –∏ >, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, —á—Ç–æ–±—ã –Ω–µ –ø—É—Ç–∞—Ç—å—Å—è\n",
    "    clean_sentence = sentence.replace('<', '').replace('>', '')\n",
    "    \n",
    "    # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Ü–∏—Ñ—Ä—ã\n",
    "    # –ï—Å–ª–∏ –≤–¥—Ä—É–≥ –≤—Å—Ç—Ä–µ—Ç–∏–º –Ω–µ–∑–Ω–∞–∫–æ–º—ã–π —Å–∏–º–≤–æ–ª, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–≥–æ (–∏–ª–∏ –ø–∞–¥–∞–µ–º, –Ω–æ –ø–æ–∫–∞ –ø—Ä–æ–ø—É—Å—Ç–∏–º)\n",
    "    return [char2idx[char] for char in clean_sentence if char in char2idx] + [EOS_token]\n",
    "\n",
    "def get_batch(batch_size=32):\n",
    "    input_list = []\n",
    "    target_list = []\n",
    "    \n",
    "    # 1. –ù–∞–±–∏—Ä–∞–µ–º batch_size —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "    for _ in range(batch_size):\n",
    "        pair = random.choice(train_data) # –ë–µ—Ä–µ–º –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "        input_str, target_str = pair\n",
    "        \n",
    "        # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å–ø–∏—Å–∫–∏ —á–∏—Å–µ–ª (–ù–ï —Ç–µ–Ω–∑–æ—Ä—ã –ø–æ–∫–∞)\n",
    "        input_idxs = indexesFromSentence(input_str)\n",
    "        target_idxs = indexesFromSentence(target_str)\n",
    "        \n",
    "        # –í–∞–∂–Ω–æ: –¥–ª—è PyTorch –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏ –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n",
    "        input_list.append(torch.tensor(input_idxs, dtype=torch.long, device=device))\n",
    "        target_list.append(torch.tensor(target_idxs, dtype=torch.long, device=device))\n",
    "        \n",
    "    # 2. –ú–∞–≥–∏—è PAD_SEQUENCE\n",
    "    # –û–Ω–∞ –±–µ—Ä–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–µ–Ω–∑–æ—Ä–æ–≤ —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã –∏ –¥–µ–ª–∞–µ—Ç –∏–∑ –Ω–∏—Ö –æ–¥–∏–Ω –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä.\n",
    "    # padding_value=PAD_token (–Ω–∞—à 0) ‚Äî —á–µ–º –∑–∞–ø–æ–ª–Ω—è—Ç—å –ø—É—Å—Ç–æ—Ç—É.\n",
    "    # –í–ê–ñ–ù–û: –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–Ω–∞ –¥–µ–ª–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (Max_Length, Batch_Size).\n",
    "    # –≠—Ç–æ —Ç–æ, —á—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è RNN (–≤—Ä–µ–º—è –∏–¥–µ—Ç –≤–Ω–∏–∑, –±–∞—Ç—á–∏ –∏–¥—É—Ç –≤–ø—Ä–∞–≤–æ).\n",
    "    input_batch = pad_sequence(input_list, padding_value=PAD_token)\n",
    "    target_batch = pad_sequence(target_list, padding_value=PAD_token)\n",
    "    \n",
    "    return input_batch, target_batch\n",
    "\n",
    "# === –¢–ï–°–¢ ===\n",
    "# –î–∞–≤–∞–π –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç –æ–¥–∏–Ω –±–∞—Ç—á\n",
    "inp, tgt = get_batch(batch_size=3)\n",
    "print(f\"–§–æ—Ä–º–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ (Seq_Len, Batch): {inp.shape}\")\n",
    "print(f\"–§–æ—Ä–º–∞ —Ü–µ–ª–µ–≤–æ–≥–æ –±–∞—Ç—á–∞ (Seq_Len, Batch): {tgt.shape}\")\n",
    "print(\"\\n–ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ (–≤–∏–¥–∏–º –Ω—É–ª–∏-–ø–∞–¥–¥–∏–Ω–≥–∏ –≤ –∫–æ–Ω—Ü–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ—Ä–∞–∑?):\")\n",
    "print(inp.transpose(0, 1)) # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (Batch, Seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ccbde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ VRAM...\n",
      "‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ VRAM GPU!\n",
      "–†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞: torch.Size([40000, 12]) (–ü—Ä–∏–º–µ—Ä–æ–≤, –î–ª–∏–Ω–∞)\n",
      "–ó–∞–Ω–∏–º–∞–µ—Ç –ø–∞–º—è—Ç–∏: 3.66 MB\n",
      "‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ VRAM: torch.Size([10000, 12])\n"
     ]
    }
   ],
   "source": [
    "# === –≠–¢–ê–ü –ü–†–ï–î-–ó–ê–ì–†–£–ó–ö–ò (ETL) ===\n",
    "# –ú—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –æ–¥–∏–Ω —Ä–∞–∑ –∏ –Ω–∞–≤—Å–µ–≥–¥–∞, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å CPU –≤ —Ü–∏–∫–ª–µ.\n",
    "\n",
    "print(\"üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ VRAM...\")\n",
    "\n",
    "def prepare_full_dataset_tensor(data_list):\n",
    "    input_tensors = []\n",
    "    target_tensors = []\n",
    "    \n",
    "    for src, tgt in data_list:\n",
    "        input_tensors.append(torch.tensor(indexesFromSentence(src), dtype=torch.long))\n",
    "        target_tensors.append(torch.tensor(indexesFromSentence(tgt), dtype=torch.long))\n",
    "    \n",
    "    # –î–µ–ª–∞–µ–º –æ–¥–∏–Ω –≥–∏–≥–∞–Ω—Ç—Å–∫–∏–π Pad –¥–ª—è –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "    # (Total_Samples, Max_Len)\n",
    "    # –í–ê–ñ–ù–û: pad_sequence –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–µ–ª–∞–µ—Ç (Len, Batch).\n",
    "    # –ù–∞–º —É–¥–æ–±–Ω–µ–µ (Batch, Len) –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è, –∞ –≤ —Ü–∏–∫–ª–µ —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º.\n",
    "    input_full = pad_sequence(input_tensors, batch_first=True, padding_value=PAD_token)\n",
    "    target_full = pad_sequence(target_tensors, batch_first=True, padding_value=PAD_token)\n",
    "    \n",
    "    return input_full.to(device), target_full.to(device)\n",
    "\n",
    "# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ —Å—Ä–∞–∑—É –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É\n",
    "train_input_gpu, train_target_gpu = prepare_full_dataset_tensor(train_data)\n",
    "\n",
    "print(f\"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ VRAM GPU!\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞: {train_input_gpu.shape} (–ü—Ä–∏–º–µ—Ä–æ–≤, –î–ª–∏–Ω–∞)\")\n",
    "print(f\"–ó–∞–Ω–∏–º–∞–µ—Ç –ø–∞–º—è—Ç–∏: {train_input_gpu.element_size() * train_input_gpu.numel() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "test_input_gpu, test_target_gpu = prepare_full_dataset_tensor(test_data)\n",
    "\n",
    "print(f\"‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ VRAM: {test_input_gpu.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5e1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(encoder, decoder, criterion, batch_size=64):\n",
    "    encoder.eval() # –í—ã–∫–ª—é—á–∞–µ–º Dropout\n",
    "    decoder.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = len(test_input_gpu) // batch_size\n",
    "    \n",
    "    with torch.no_grad(): # –ù–µ —Ö—Ä–∞–Ω–∏–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã (—ç–∫–æ–Ω–æ–º–∏–º –ø–∞–º—è—Ç—å)\n",
    "        for i in range(num_batches):\n",
    "            # –ë–µ—Ä–µ–º –±–∞—Ç—á–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            \n",
    "            # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º, —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å (Batch, Seq) -> (Seq, Batch)\n",
    "            input_batch = test_input_gpu[start:end].transpose(0, 1)\n",
    "            target_batch = test_target_gpu[start:end].transpose(0, 1)\n",
    "            \n",
    "            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–≤–æ—é —Ñ—É–Ω–∫—Ü–∏—é, –Ω–æ –Ω—É–∂–Ω–æ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç loss\n",
    "            # –í–Ω–∏–º–∞–Ω–∏–µ: train_batch_packed –¥–µ–ª–∞–µ—Ç backward(). –ù–∞–º —ç—Ç–æ –ù–ï –Ω—É–∂–Ω–æ.\n",
    "            # –ü–æ—ç—Ç–æ–º—É —Å–∫–æ–ø–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É —Ä–∞—Å—á–µ—Ç–∞ Loss —Å—é–¥–∞, –Ω–æ –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞.\n",
    "            \n",
    "            # --- –õ–û–ì–ò–ö–ê –†–ê–°–ß–ï–¢–ê (–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è train_batch_packed –±–µ–∑ backward) ---\n",
    "            lengths = (input_batch.transpose(0, 1) != PAD_token).sum(dim=1).cpu()\n",
    "            encoder_hidden = encoder.initHidden(batch_size)\n",
    "            encoder_outputs, encoder_hidden = encoder(input_batch, lengths, encoder_hidden)\n",
    "            \n",
    "            mask = (input_batch.transpose(0, 1) != PAD_token)\n",
    "            full_mask = torch.zeros(batch_size, decoder.max_length, dtype=torch.bool, device=device)\n",
    "            limit_len = min(mask.size(1), decoder.max_length)\n",
    "            full_mask[:, :limit_len] = mask[:, :limit_len]\n",
    "            \n",
    "            proj_encoder_outputs = torch.zeros(decoder.max_length, batch_size, encoder.hidden_size, device=device)\n",
    "            out_len = encoder_outputs.size(0) \n",
    "            limit_copy = min(out_len, decoder.max_length)\n",
    "            proj_encoder_outputs[:limit_copy, :, :] = encoder_outputs[:limit_copy, :, :]\n",
    "            \n",
    "            decoder_input = torch.tensor([[SOS_token] * batch_size], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "            batch_loss = 0.0\n",
    "            \n",
    "            target_len = target_batch.size(0)\n",
    "            for di in range(target_len):\n",
    "                decoder_output, decoder_hidden, _ = decoder(\n",
    "                    decoder_input, decoder_hidden, proj_encoder_outputs, encoder_mask=full_mask)\n",
    "                batch_loss += criterion(decoder_output, target_batch[di])\n",
    "                # Teacher forcing –Ω–µ –Ω—É–∂–µ–Ω –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.transpose(0, 1).detach()\n",
    "            \n",
    "            total_loss += (batch_loss.item() / target_len)\n",
    "            \n",
    "    encoder.train() # –í–æ–∑–≤—Ä–∞—â–∞–µ–º Dropout –æ–±—Ä–∞—Ç–Ω–æ\n",
    "    decoder.train()\n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "scaler = GradScaler() # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–≤–Ω–µ —Ü–∏–∫–ª–∞)\n",
    "\n",
    "\n",
    "# === CONFIG ===\n",
    "BATCH_SIZE = 256\n",
    "learning_rate = 0.005\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç\n",
    "EPOCHS = 40  # –•–æ—Ç–∏–º –ø—Ä–æ–≥–Ω–∞—Ç—å —É—á–µ–±–Ω–∏–∫ 40 —Ä–∞–∑\n",
    "train_size = len(train_data) \n",
    "\n",
    "# –°–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –≤ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–µ?\n",
    "steps_per_epoch = train_size // BATCH_SIZE\n",
    "\n",
    "n_iters = int(steps_per_epoch * EPOCHS)\n",
    "\n",
    "print(f\"–ü—Ä–∏ Batch Size {BATCH_SIZE} –∏ {EPOCHS} —ç–ø–æ—Ö–∞—Ö:\")\n",
    "print(f\"–ù–∞–º –Ω—É–∂–Ω–æ {n_iters} –∏—Ç–µ—Ä–∞—Ü–∏–π.\")\n",
    "\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–ù–æ–≤—ã–π –¥–µ–∫–æ–¥–µ—Ä!)\n",
    "encoder_batch = EncoderRNN_Packed(vocab_size, 128).to(device)\n",
    "decoder_batch = AttnDecoderRNN_Masked(128, vocab_size, max_length=15, dropout_p=0.1).to(device)\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#encoder_batch.compile();\n",
    "#decoder_batch.compile();\n",
    "\n",
    "enc_optim = optim.Adam(encoder_batch.parameters(), lr=learning_rate)\n",
    "dec_optim = optim.Adam(decoder_batch.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(ignore_index=PAD_token)\n",
    "\n",
    "print_every = n_iters // 10 \n",
    "\n",
    "# –ó–∞—â–∏—Ç–∞ –æ—Ç –¥—É—Ä–∞–∫–∞: –µ—Å–ª–∏ –∏—Ç–µ—Ä–∞—Ü–∏–π –æ—á–µ–Ω—å –º–∞–ª–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 5), —Ç–æ –ø–∏—à–µ–º –∫–∞–∂–¥—ã–π —Ä–∞–∑\n",
    "if print_every == 0:\n",
    "    print_every = 1\n",
    "\n",
    "current_loss = 0\n",
    "plot_losses = []\n",
    "start = time.time()\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "\n",
    "print(f\"üìù –õ–æ–≥–∏ –±—É–¥—É—Ç –≤—ã–≤–æ–¥–∏—Ç—å—Å—è –∫–∞–∂–¥—ã–µ {print_every} —à–∞–≥–æ–≤.\")\n",
    "\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    indices = torch.randint(0, len(train_input_gpu), (BATCH_SIZE,), device=device)\n",
    "    input_batch = train_input_gpu[indices].transpose(0, 1)\n",
    "    target_batch = train_target_gpu[indices].transpose(0, 1)\n",
    "    \n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é train_batch_packed\n",
    "\n",
    "    loss = train_batch_packed(input_batch, target_batch, encoder_batch, decoder_batch,\n",
    "                       enc_optim, dec_optim, criterion,scaler)\n",
    "    \n",
    "        \n",
    "    plot_losses.append(loss)\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        speed = (iter * BATCH_SIZE) / (time.time() - start)\n",
    "        print(f'{iter} | Loss: {loss:.5f} | Speed: {speed:.0f} samples/sec')\n",
    "\n",
    "\n",
    "    if iter % steps_per_epoch == 0: \n",
    "        current_epoch = iter // steps_per_epoch\n",
    "\n",
    "        val_loss = validate_model(encoder_batch, decoder_batch, criterion)\n",
    "        print(f\"   ‚≠êÔ∏è –≠–ø–æ—Ö–∞ {current_epoch} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. Val Loss: {val_loss:.5f}\")\n",
    "\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(f\"‚èπÔ∏è –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {iter}!\")\n",
    "                break\n",
    "\n",
    "print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ab308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è (—Å–≤–µ—Ä—Ç–∫–∞)\n",
    "def moving_average(data, window_size=50):\n",
    "    # window_size=50 –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∫–∞–∂–¥–∞—è —Ç–æ—á–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞ - —ç—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ –∑–∞ 50 —à–∞–≥–æ–≤\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –∫ —Ç–≤–æ–µ–º—É —Å–ø–∏—Å–∫—É –æ—à–∏–±–æ–∫\n",
    "smooth_losses = moving_average(plot_losses)\n",
    "\n",
    "# –†–∏—Å—É–µ–º\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(smooth_losses, label='Smoothed Loss')\n",
    "plt.title(\"–ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è (–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ)\")\n",
    "plt.xlabel(\"–ò—Ç–µ—Ä–∞—Ü–∏–∏\")\n",
    "plt.ylabel(\"–û—à–∏–±–∫–∞\")\n",
    "plt.grid(True, alpha=0.3) # –î–æ–±–∞–≤–∏–º —Å–µ—Ç–∫—É –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "# === –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø (–° –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–∞—Å–æ–∫) ===\n",
    "\n",
    "def evaluate(input_sentence):\n",
    "    encoder_batch.eval()\n",
    "    decoder_batch.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_sentence)\n",
    "        # –î–ª–∏–Ω–∞ –≤—Å–µ–≥–¥–∞ —Ä–∞–≤–Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ —Ç–µ–Ω–∑–æ—Ä–∞\n",
    "        length = torch.tensor([input_tensor.size(0)]) \n",
    "        \n",
    "        encoder_hidden = encoder_batch.initHidden(batch_size=1)\n",
    "        \n",
    "        # –ü–µ—Ä–µ–¥–∞–µ–º length!\n",
    "        encoder_outputs, encoder_hidden = encoder_batch(input_tensor, length, encoder_hidden)\n",
    "        \n",
    "        # ... (–æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...\n",
    "        # (–ù–µ –∑–∞–±—É–¥—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –æ—Å—Ç–∞—Ç–æ–∫ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –ø—Ä–æ—à–ª–æ–π –≤–µ—Ä—Å–∏–∏, –≥–¥–µ –º—ã –¥–µ–ª–∞–ª–∏ –º–∞—Å–∫–∏)\n",
    "        # –î–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏: –∏—Å–ø–æ–ª—å–∑—É–π —Ç—É –∂–µ –ª–æ–≥–∏–∫—É proj_encoder_outputs –∏ encoder_mask, —á—Ç–æ –±—ã–ª–∞\n",
    "        \n",
    "        # --- (–ö–æ–ø–∏–ø–∞—Å—Ç —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞ –Ω–∏–∂–µ –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã) ---\n",
    "        proj_encoder_outputs = torch.zeros(decoder_batch.max_length, 1, encoder_batch.hidden_size, device=device)\n",
    "        out_len = encoder_outputs.size(0)\n",
    "        limit_copy = min(out_len, decoder_batch.max_length)\n",
    "        proj_encoder_outputs[:limit_copy, :, :] = encoder_outputs[:limit_copy, :, :]\n",
    "\n",
    "        encoder_mask = torch.zeros(1, decoder_batch.max_length, dtype=torch.bool, device=device)\n",
    "        encoder_mask[:, :limit_copy] = True\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(decoder_batch.max_length, decoder_batch.max_length)\n",
    "\n",
    "        for di in range(decoder_batch.max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder_batch(\n",
    "                decoder_input, decoder_hidden, proj_encoder_outputs, encoder_mask=encoder_mask)\n",
    "            decoder_attentions[di] = decoder_attention.data[0]\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(idx2char[topi.item()])\n",
    "            decoder_input = topi.detach().transpose(0, 1)\n",
    "            \n",
    "    encoder_batch.train()\n",
    "    decoder_batch.train()\n",
    "    return \"\".join(decoded_words), decoder_attentions[:di + 1]\n",
    "\n",
    "# –≠—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –Ω–æ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –Ω–æ–≤–æ–π evaluate\n",
    "def evaluate_randomly(n=5):\n",
    "    print(f\"\\nüéì –≠–ö–ó–ê–ú–ï–ù (Masked Model):\")\n",
    "    correct = 0\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_data)\n",
    "        src = pair[0]\n",
    "        tgt_real = pair[1]\n",
    "        \n",
    "        output_words, _ = evaluate(src)\n",
    "        \n",
    "        tgt_clean = tgt_real.replace('<','').replace('>','')\n",
    "        out_clean = output_words.replace('<EOS>','')\n",
    "        \n",
    "        is_match = \"‚úÖ\" if tgt_clean == out_clean else f\"‚ùå ({tgt_clean})\"\n",
    "        if tgt_clean == out_clean: correct += 1\n",
    "        print(f\"{src.ljust(15)} -> {out_clean.ljust(12)} {is_match}\")\n",
    "    print(f\"–¢–æ—á–Ω–æ—Å—Ç—å: {correct}/{n}\")\n",
    "\n",
    "def showAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "    clean_output = output_words.replace('<EOS>', '')\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.set_xticks(range(len([''] + list(input_sentence))))\n",
    "    ax.set_yticks(range(len([''] + list(clean_output))))\n",
    "\n",
    "    ax.set_xticklabels([''] + list(input_sentence), rotation=90)\n",
    "    ax.set_yticklabels([''] + list(clean_output))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# === –§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ ===\n",
    "evaluate_randomly(100)\n",
    "print(\"\\n--- –ü—Ä–æ–≤–µ—Ä–∫–∞ –í–Ω–∏–º–∞–Ω–∏—è ---\")\n",
    "showAttention(\"1 Jan 2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64490d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ (Device: NVIDIA GeForce RTX 5070 Ti) ---\n",
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö: Batch=256, SeqLen=50, VocabLimit=69\n",
      "–†–∞–∑–æ–≥—Ä–µ–≤ (10 –∏—Ç–µ—Ä–∞—Ü–∏–π)...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 256, 128), got [2, 256, 128]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–†–∞–∑–æ–≥—Ä–µ–≤ (10 –∏—Ç–µ—Ä–∞—Ü–∏–π)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m     \u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–ó–∞–º–µ—Ä —Å–∫–æ—Ä–æ—Å—Ç–∏ (100 –∏—Ç–µ—Ä–∞—Ü–∏–π)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 63\u001b[0m, in \u001b[0;36mrun_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# –í—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m output, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# \"–•–∞–∫\" –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ª–æ—Å—Å–∞: –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤—ã—Ö–æ–¥\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# –ï—Å–ª–∏ output –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä (Seq, Batch, Hidden) –∏–ª–∏ (Batch, Seq, Hidden)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m~/ai_lab/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_lab/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m, in \u001b[0;36mEncoderRNN_Packed.forward\u001b[0;34m(self, input, lengths, hidden)\u001b[0m\n\u001b[1;32m     20\u001b[0m packed \u001b[38;5;241m=\u001b[39m pack_padded_sequence(embedded, lengths\u001b[38;5;241m.\u001b[39mcpu(), enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 2. –ü–†–û–ì–û–ù (—É–∂–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 3. –†–ê–°–ü–ê–ö–û–í–ö–ê (UNPACKING)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å—ë –≤ –ø—Ä–∏–≤—ã—á–Ω—ã–π –≤–∏–¥ (—Å –Ω—É–ª—è–º–∏), —á—Ç–æ–±—ã –î–µ–∫–æ–¥–µ—Ä –º–æ–≥ —Ä–∞–±–æ—Ç–∞—Ç—å\u001b[39;00m\n\u001b[1;32m     27\u001b[0m output, _ \u001b[38;5;241m=\u001b[39m pad_packed_sequence(output)\n",
      "File \u001b[0;32m~/ai_lab/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_lab/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/ai_lab/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1392\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1388\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m   1389\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m   1390\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m-> 1392\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[1;32m   1395\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1396\u001b[0m         hx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[1;32m   1404\u001b[0m     )\n",
      "File \u001b[0;32m~/ai_lab/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:367\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m    365\u001b[0m expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_hidden_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_lab/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:348\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_hidden_size\u001b[39m(\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    343\u001b[0m     hx: Tensor,\n\u001b[1;32m    344\u001b[0m     expected_hidden_size: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    345\u001b[0m     msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    346\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[0;32m--> 348\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 256, 128), got [2, 256, 128]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# --- –í–ê–®–ò –ò–ú–ü–û–†–¢–´ ---\n",
    "# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∫–ª–∞—Å—Å EncoderRNN_Packed –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –∏–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤—ã—à–µ\n",
    "# from your_module import EncoderRNN_Packed \n",
    "\n",
    "# 1. –ù–ê–°–¢–†–û–ô–ö–ò\n",
    "BATCH_SIZE = 256\n",
    "SEQ_LEN = 50 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "HIDDEN_DIM = 128 # –†–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è –∏–∑ –≤–∞—à–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞\n",
    "\n",
    "print(f\"--- –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ (Device: {torch.cuda.get_device_name(0)}) ---\")\n",
    "\n",
    "# 2. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ò\n",
    "# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ vocab_size –æ–ø—Ä–µ–¥–µ–ª–µ–Ω —É –≤–∞—Å —Ä–∞–Ω–µ–µ. \n",
    "# –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –∑–∞–º–µ–Ω–∏—Ç–µ vocab_size –Ω–∞ —á–∏—Å–ª–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä 10000.\n",
    "try:\n",
    "    model = EncoderRNN_Packed(vocab_size, HIDDEN_DIM).to(DEVICE)\n",
    "except NameError:\n",
    "    print(\"–í–Ω–∏–º–∞–Ω–∏–µ: vocab_size –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º 10000 –¥–ª—è —Ç–µ—Å—Ç–∞\")\n",
    "    vocab_size = 10000\n",
    "    model = EncoderRNN_Packed(vocab_size, HIDDEN_DIM).to(DEVICE)\n",
    "\n",
    "model.train()\n",
    "\n",
    "# 3. –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–ù–ù–´–•\n",
    "# –£–∑–Ω–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è –∏–∑ –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –Ω–µ –≤—ã–ª–µ—Ç–µ—Ç—å –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã\n",
    "try:\n",
    "    # –ò—â–µ–º —Å–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (–æ–±—ã—á–Ω–æ self.embedding)\n",
    "    real_vocab_limit = model.embedding.num_embeddings\n",
    "except AttributeError:\n",
    "    # –ï—Å–ª–∏ –∏–º—è —Å–ª–æ—è –¥—Ä—É–≥–æ–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π vocab_size\n",
    "    real_vocab_limit = vocab_size\n",
    "\n",
    "print(f\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö: Batch={BATCH_SIZE}, SeqLen={SEQ_LEN}, VocabLimit={real_vocab_limit}\")\n",
    "\n",
    "# –í–ê–ñ–ù–û: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º (SEQ_LEN, BATCH_SIZE). \n",
    "# PyTorch RNN –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∂–¥—É—Ç [Length, Batch, ...], –µ—Å–ª–∏ –Ω–µ batch_first=True\n",
    "data_batch = torch.randint(0, real_vocab_limit, (SEQ_LEN, BATCH_SIZE), device=DEVICE)\n",
    "\n",
    "# –î–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (–≤—Å–µ –ø–æ–ª–Ω—ã–µ)\n",
    "lengths_batch = torch.full((BATCH_SIZE,), SEQ_LEN, dtype=torch.long, device='cpu')\n",
    "\n",
    "# –°–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: (Layers, Batch, Hidden)\n",
    "# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º 2 —Å–ª–æ—è (–∫–∞–∫ —á–∞—Å—Ç–æ –±—ã–≤–∞–µ—Ç). –ï—Å–ª–∏ —É–ø–∞–¥–µ—Ç - –ø–æ–º–µ–Ω—è–µ–º –Ω–∞ 1 –∏–ª–∏ 4.\n",
    "N_LAYERS = 1 \n",
    "hidden_batch = torch.zeros(N_LAYERS, BATCH_SIZE, HIDDEN_DIM, device=DEVICE)\n",
    "\n",
    "# –¶–µ–ª–∏ –∏ –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
    "target_dummy = torch.randint(0, 10, (BATCH_SIZE,), device=DEVICE) # –ü—Ä–æ—Å—Ç–æ –¥–ª—è –ª–æ—Å—Å–∞\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 4. –§–£–ù–ö–¶–ò–Ø –®–ê–ì–ê\n",
    "def run_step():\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # –í—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏\n",
    "    output, _ = model(data_batch, lengths_batch, hidden_batch)\n",
    "    \n",
    "    # \"–•–∞–∫\" –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ª–æ—Å—Å–∞: –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤—ã—Ö–æ–¥\n",
    "    # –ï—Å–ª–∏ output –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä (Seq, Batch, Hidden) –∏–ª–∏ (Batch, Seq, Hidden)\n",
    "    if output.dim() == 3:\n",
    "        output = output[-1] # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥\n",
    "    \n",
    "    # –ü–æ–¥–≥–æ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–µ–π–∫–æ–≤–æ–≥–æ –ª–æ—Å—Å–∞ (–ø—Ä–æ—Å—Ç–æ —á—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å GPU)\n",
    "    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç –ø–æ–¥ —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞\n",
    "    dummy_target = torch.randint(0, output.size(-1), (BATCH_SIZE,), device=DEVICE)\n",
    "    \n",
    "    loss = criterion(output, dummy_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 5. –ó–ê–ü–£–°–ö\n",
    "print(\"–†–∞–∑–æ–≥—Ä–µ–≤ (10 –∏—Ç–µ—Ä–∞—Ü–∏–π)...\")\n",
    "for _ in range(10):\n",
    "    run_step()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "print(\"–ó–∞–º–µ—Ä —Å–∫–æ—Ä–æ—Å—Ç–∏ (100 –∏—Ç–µ—Ä–∞—Ü–∏–π)...\")\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(100):\n",
    "    run_step()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"–ì–æ—Ç–æ–≤–æ! –í—Ä–µ–º—è: {end - start:.2f} —Å–µ–∫\")\n",
    "print(\"–°–ú–û–¢–†–ò–¢–ï –ó–ê–ì–†–£–ó–ö–£ GPU –ü–†–Ø–ú–û –°–ï–ô–ß–ê–°.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
